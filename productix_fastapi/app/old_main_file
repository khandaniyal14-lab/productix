# fastapi_app.py
import json
from pydantic import BaseModel, EmailStr, Field
from typing import Dict, Any, List, Optional
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError
import logging
from .database import Base, engine, get_db
from .models import User,Organization, AIData, ProductivityCalculation, AIAnalysis,ChatbotHistory, AIReport, Base, Product, Batch, ShiftEntry, ShiftEnum, BatchStatus
from .schemas import SignUpSchema, LoginSchema, TokenSchema
from .auth import hash_password, verify_password, create_access_token
from .deps import  get_current_user
from fastapi.security import HTTPBearer
from fastapi import BackgroundTasks, status
from fastapi.responses import JSONResponse
from .email_utlis import FRONTEND_VERIFY_URL, send_verification_email
from .auth_utlis import create_verification_token, verify_verification_token
from fastapi import FastAPI, Depends, HTTPException, status,  APIRouter
from datetime import date # your JWT dependency
from sqlalchemy import func
from fastapi.responses import RedirectResponse
from .core_logic import ai_batch_analysis, ai_product_trend, rag_chat_response
import pandas as pd
from fastapi.responses import FileResponse
import os

router = APIRouter()
security = HTTPBearer()
Base.metadata.create_all(bind=engine)
# Import the core logic functions from the file we just created
from .core_logic import (
    perform_calculation,
    get_ai_analysis,
    get_rag_chatbot_response,
    get_ai_agent_report
)
app = FastAPI(
    title="Productix AI & Calculation Engine",
    description="A high-performance API for all productivity calculations and AI-driven analysis features of the Productix application.",
    version="1.0.0"
)
origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    # add production URL here later, e.g. "https://yourdomain.com"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,       # Allowed origins
    allow_credentials=True,
    allow_methods=["*"],         # Allow all HTTP methods
    allow_headers=["*"],         # Allow all headers
)

# --- Pydantic Models for Request & Response Validation ---
# These models define the expected structure of the data for each endpoint.

class ChatbotRequest(BaseModel):
    query: str

class Calculate(BaseModel):
    inputs: Dict[str, float]   # e.g., {"Electricity Consumption": 20}
    outputs: Dict[str, float]

class AnalysisRequest(BaseModel):
    """Defines the expected JSON for an /analyze request."""
    combined_productivity: str
    single_productivity: Dict[str, str]
    inputs: Dict[str, Any]
    outputs: Dict[str, Any]
    targeted_productivity: str | None = None
    standard_productivity: str | None = None



class AgentRequest(BaseModel):
    """Defines the expected JSON for an /agent request."""
    records: Dict[str, List[Dict[str, Any]]]
    goal: str = Field(..., example="Find the root cause of our declining efficiency across all products.")



# ------------------------
# Pydantic Schemas
# ------------------------

class ProductCreateSchema(BaseModel):
    name: str
    description: str = None

class BatchCreateSchema(BaseModel):
    product_id: int
    start_date: date

class ProductResponseSchema(BaseModel):
    id: int
    name: str
    description: Optional[str] = None

    class Config:
        orm_mode = True


class ProductUpdateSchema(BaseModel):
    name: Optional[str] = None
    description: Optional[str] = None


class ShiftEntryCreateSchema(BaseModel):
    batch_id: int
    date: date
    shift_no: ShiftEnum
    energy_kwh: float
    unit_price_kwh: float
    machine_hours: float
    unit_price_machine_hour: float
    worker_hours: float
    unit_price_worker_hour: float
    output_units: int

class BatchResponseSchema(BaseModel):
    id: int
    batch_no: str
    product_id: int
    start_date: date
    end_date: Optional[date] = None
    status: BatchStatus
    product: Optional[ProductResponseSchema]  # ðŸ‘ˆ include full product

    class Config:
        orm_mode = True

# --- API Endpoints ---

@app.post("/calculate", summary="Calculate Productivity Scores")
def calculate_productivity(
    request: Calculate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    # Perform calculation
    result = perform_calculation(request.inputs, request.outputs)
    if "error" in result:
        raise HTTPException(status_code=400, detail=result["error"])

    # Save output in DB
    calc = ProductivityCalculation(
        tenant_id=current_user.tenant_id,
        user_id=current_user.id,
        processed_inputs=request.inputs,
        processed_outputs=request.outputs,
        combined_productivity=result["combined_productivity"],
        single_productivity=result["single_productivity"]
    )
    db.add(calc)
    db.commit()
    db.refresh(calc)

    return result


@app.post("/analyze", summary="Get Structured AI Analysis")
def analyze_calculation(
    request: AnalysisRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    # Perform AI analysis
    result = get_ai_analysis(request.dict())
    if "error" in result:
        raise HTTPException(status_code=500, detail=result["error"])

    # Save output in DB
    analysis = AIAnalysis(
        tenant_id=current_user.tenant_id,
        user_id=current_user.id,
        request_data=request.dict(),
        efficiency_score=result.get("efficiency_score"),
        ai_prediction=result.get("ai_prediction"),
        top_inefficiencies=result.get("top_inefficiencies"),
        ai_prescriptions=result.get("ai_prescriptions")
    )
    db.add(analysis)
    db.commit()
    db.refresh(analysis)

    return result


"""@app.post("/chatbot", summary="Run RAG Chatbot")
def run_chatbot(
    request: ChatbotRequest,
    db: Session = Depends(get_db),
    current_user: "User" = Depends(get_current_user)
):
    # --- DEBUG PRINTS ---
   

    # Only include tenant-specific records if using DB
    tenant_records = request.records  # or filter/query DB if persistent records are stored

    # Generate chatbot response
    result = get_rag_chatbot_response(tenant_records, request.query)
    if "error" in result:
        raise HTTPException(status_code=500, detail=result["error"])

    # Save chatbot session in DB
    convo = ChatbotHistory(
        tenant_id=current_user.tenant_id,
        user_id=current_user.id,
        records=request.records,
        query=request.query,
        response=result["response"]
    )
    db.add(convo)
    db.commit()
    db.refresh(convo)

    return result"""

@app.post("/agent", summary="Run AI Agent for Reporting")
def run_ai_agent(
    request: AgentRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    # Only include tenant-specific records if using DB
    tenant_records = request.records  # or query DB if persistent records are saved

    # Generate report
    result = get_ai_agent_report(tenant_records, request.goal)
    if "error" in result:
        raise HTTPException(status_code=500, detail=result["error"])

    # Save report in DB
    report = AIReport(
        tenant_id=current_user.tenant_id,
        user_id=current_user.id,
        records_used=request.records,
        goal=request.goal,
        plan=result["plan"],
        report=result["report"]
    )
    db.add(report)
    db.commit()
    db.refresh(report)

    return result

# Optional: Explicitly add security scheme to OpenAPI
@app.get("/")
async def root():
    return {"message": "Hello World"}


logger = logging.getLogger(__name__)





@app.post("/signup", status_code=status.HTTP_201_CREATED)
async def signup(user: SignUpSchema, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """
    Register a new user and create a tenant. Send verification email.
    """
    try:
        existing_user = db.query(User).filter(User.email == user.email).first()
        if existing_user:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Email already registered")

        if len(user.password) < 8:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Password must be at least 8 characters long")

        with db.begin_nested():
            tenant = Tenant(name=user.name)
            db.add(tenant)
            db.flush()

            hashed_password = hash_password(user.password)
            new_user = User(
                name=user.name,
                email=user.email,
                password_hash=hashed_password,
                tenant_id=tenant.id,
                is_verified=True
            )
            db.add(new_user)

        db.commit()
        db.refresh(tenant)
        db.refresh(new_user)

        # generate verification token (JWT)
        token = create_verification_token(new_user.id)

        # send verification email in background
        background_tasks.add_task(send_verification_email, new_user.email, token)

        logger.info(f"New user registered (unverified): {user.email} tenant={tenant.id}")

        # Return non-sensitive response instructing to check email
        return JSONResponse(status_code=status.HTTP_201_CREATED, content={
            "message": "Account created. Check your email to verify your account."
        })

    except IntegrityError:
        db.rollback()
        logger.error(f"Integrity error during signup for email: {user.email}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Registration failed due to database constraints"
        )



@app.get("/verify-email")
async def verify_email(token: str, db: Session = Depends(get_db)):
    user_id = verify_verification_token(token)  # will raise HTTPException if invalid/expired
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="User not found")

    if user.is_verified:
        # Already verified â€” redirect to frontend success page or return JSON
        return RedirectResponse(url=f"{FRONTEND_VERIFY_URL}?status=already_verified")

    user.is_verified = True
    db.add(user)
    db.commit()

    # redirect to frontend success page (recommended)
    return RedirectResponse(url=f"{FRONTEND_VERIFY_URL}?status=success")

@app.post("/login", response_model=TokenSchema)
async def login(credentials: LoginSchema, db: Session = Depends(get_db)):
    try:
        user = db.query(User).filter(User.email == credentials.email).first()
        
        if not user or not verify_password(credentials.password, user.password_hash):
            logger.warning(f"Failed login attempt for email: {credentials.email}")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid credentials",
                headers={"WWW-Authenticate": "Bearer"},
            )

        # Require email verification
        if not getattr(user, "is_verified", False):
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Email not verified. Please check your inbox.",
                headers={"WWW-Authenticate": "Bearer"},
            )

        if hasattr(user, 'is_active') and not user.is_active:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Account deactivated",
                headers={"WWW-Authenticate": "Bearer"},
            )

        access_token = create_access_token({"user_id": user.id, "tenant_id": user.tenant_id})
        logger.info(f"Successful login for user: {user.email}")
        return {"access_token": access_token, "token_type": "bearer"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during login: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Internal server error during authentication"
        )

@app.post("/resend-verification")
async def resend_verification(email: EmailStr, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.email == email).first()
    # For UX/security: respond identically whether user exists or not to avoid enumeration,
    # but only send email if user exists and not verified.
    if user and not user.is_verified:
        token = create_verification_token(user.id)
        background_tasks.add_task(send_verification_email, user.email, token)
    return {"message": "If an account with that email exists, a verification email has been sent."}


@app.get("/productivity-records", summary="Fetch productivity records for logged-in tenant")
def get_productivity_records(
    db: Session = Depends(get_db),
    current_user: "User" = Depends(get_current_user)
) -> Dict[str, List[Dict]]:
    """
    Returns all productivity records for the current user's tenant.
    Output format is a dictionary keyed by product name.
    """
    tenant_id = current_user.tenant_id

    # Query productivity calculations for this tenant
    records = db.query(ProductivityCalculation).filter(
        ProductivityCalculation.tenant_id == tenant_id
    ).all()

    # Convert SQLAlchemy objects to dict
    records_dict: Dict[str, List[Dict]] = {}

    for r in records:
        # Assuming each calculation has a 'processed_outputs' dict with product keys
        for product_name, product_data in r.processed_outputs.items():
            if product_name not in records_dict:
                records_dict[product_name] = []
            # Combine inputs and outputs if needed
            combined_record = {
                "batch_no": r.id,  # or another identifier if you have batch_no
                "date": r.created_at.isoformat() if hasattr(r, 'created_at') else None,
                "inputs": r.processed_inputs,
                "outputs": r.processed_outputs,
                "combined": r.combined_productivity,   # string
                "single": r.single_productivity 
            }
            records_dict[product_name].append(combined_record)

    return records_dict

@app.get("/analysis-count", summary="Get count of AI analyses for tenant")
def get_analysis_count(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    count = db.query(AIAnalysis).filter(
        AIAnalysis.tenant_id == current_user.tenant_id
    ).count()
    return {"analysis_count": count}

@app.get("/products")
def list_products(db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    return db.query(Product).filter_by(tenant_id=tenant.id).all()

@app.post("/products", response_model=ProductResponseSchema)
def create_product(product: ProductCreateSchema, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    new_product = Product(
        tenant_id=tenant.id,
        name=product.name,
        description=product.description
    )
    db.add(new_product)
    db.commit()
    db.refresh(new_product)
    return new_product
@app.put("/products/{product_id}")
def update_product(
    product_id: int,
    product_data: ProductUpdateSchema,  # your Pydantic model
    db: Session = Depends(get_db),
    tenant: Tenant = Depends(get_current_user),
):
    product = db.query(Product).filter_by(id=product_id, tenant_id=tenant.id).first()
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")

    for key, value in product_data.dict(exclude_unset=True).items():
        setattr(product, key, value)

    db.commit()
    db.refresh(product)
    return product


def generate_batch_no(db: Session, product_id: int):
    last_batch = (
        db.query(Batch)
        .filter(Batch.product_id == product_id)
        .order_by(Batch.id.desc())
        .first()
    )
    if last_batch:
        new_no = str(int(last_batch.batch_no) + 1).zfill(3)
    else:
        new_no = "001"
    return new_no

@app.post("/batches", response_model=BatchResponseSchema)
def create_batch(batch_data: BatchCreateSchema, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    # Check product belongs to tenant
    product = db.query(Product).filter(Product.id == batch_data.product_id, Product.tenant_id == tenant.id).first()
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")

    batch_no = generate_batch_no(db, batch_data.product_id)

    new_batch = Batch(
        tenant_id=tenant.id,
        product_id=batch_data.product_id,
        batch_no=batch_no,
        start_date=batch_data.start_date,
        status=BatchStatus.open
    )
    db.add(new_batch)
    db.commit()
    db.refresh(new_batch)
    return new_batch

@app.get("/batches")
def get_batches(
    product_id: Optional[int] = None,
    db: Session = Depends(get_db),
    tenant: Tenant = Depends(get_current_user)
):
    query = db.query(Batch).filter(Batch.tenant_id == tenant.id)
    if product_id:
        query = query.filter(Batch.product_id == product_id)
    return query.all()

@app.get("/products/{product_id}/batches")
def get_batches(product_id: int, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    query = db.query(Batch).filter(Batch.tenant_id == tenant.id, Batch.product_id == product_id)
    return query.all()


@app.put("/batches/{batch_id}/close", response_model=BatchResponseSchema)
def close_batch(
    batch_id: int,
    db: Session = Depends(get_db),
    tenant=Depends(get_current_user)
):
    batch = db.query(Batch).filter(
        Batch.id == batch_id, Batch.tenant_id == tenant.id
    ).first()

    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    if batch.status == "closed":
        raise HTTPException(status_code=400, detail="Batch already closed")

    batch.status = "closed"
    batch.end_date = date.today()
    db.commit()
    db.refresh(batch)

    return batch   # âœ… now serialized with product.name



@app.post("/shift_entries")
def add_shift_entry(entry: ShiftEntryCreateSchema, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    # Validate batch belongs to tenant
    batch = db.query(Batch).filter(Batch.id == entry.batch_id, Batch.tenant_id == tenant.id).first()
    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    # Calculate costs
    energy_cost = entry.energy_kwh * entry.unit_price_kwh
    machine_cost = entry.machine_hours * entry.unit_price_machine_hour
    worker_cost = entry.worker_hours * entry.unit_price_worker_hour
    total_cost = energy_cost + machine_cost + worker_cost

    new_entry = ShiftEntry(
        tenant_id=tenant.id,
        batch_id=entry.batch_id,
        date=entry.date,
        shift_no=entry.shift_no,
        energy_kwh=entry.energy_kwh,
        unit_price_kwh=entry.unit_price_kwh,
        machine_hours=entry.machine_hours,
        unit_price_machine_hour=entry.unit_price_machine_hour,
        worker_hours=entry.worker_hours,
        unit_price_worker_hour=entry.unit_price_worker_hour,
        output_units=entry.output_units,
        energy_cost=energy_cost,
        machine_cost=machine_cost,
        worker_cost=worker_cost,
        total_cost=total_cost
    )
    db.add(new_entry)
    db.commit()
    db.refresh(new_entry)
    return {"message": "Shift entry added successfully", "shift_entry_id": new_entry.id}

@app.get("/batches/{batch_id}/report")
def get_batch_report(batch_id: int, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    batch = db.query(Batch).filter(Batch.id == batch_id, Batch.tenant_id == tenant.id).first()
    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    shift_entries = db.query(ShiftEntry).filter(ShiftEntry.batch_id == batch.id).all()
    total_energy = sum(entry.energy_kwh for entry in shift_entries)
    total_machine = sum(entry.machine_hours for entry in shift_entries)
    total_worker = sum(entry.worker_hours for entry in shift_entries)
    total_output = sum(entry.output_units for entry in shift_entries)
    total_cost = sum(entry.total_cost for entry in shift_entries)
    cost_per_unit = total_cost / total_output if total_output > 0 else 0
    productivity = total_output / total_cost if total_cost > 0 else 0

    return {
        "batch_id": batch.id,
        "batch_no": batch.batch_no,
        "product_id": batch.product_id,
        "status": batch.status,
        "total_energy": total_energy,
        "total_machine": total_machine,
        "total_worker": total_worker,
        "total_output": total_output,
        "total_cost": total_cost,
        "cost_per_unit": cost_per_unit,
        "productivity_ratio": productivity
    }

@app.get("/batches/{batch_id}/trend")
def get_shift_trend(batch_id: int, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    entries = (
        db.query(ShiftEntry)
        .filter(ShiftEntry.batch_id == batch_id, ShiftEntry.tenant_id == tenant.id)
        .order_by(ShiftEntry.date.desc(), ShiftEntry.shift_no.desc())
        .limit(3)
        .all()
    )

    trend_data = [
        {
            "date": entry.date,
            "shift": entry.shift_no.value,
            "output_units": entry.output_units,
            "total_cost": float(entry.total_cost),
            "productivity_ratio": float(entry.output_units / entry.total_cost) if entry.total_cost > 0 else 0
        }
        for entry in reversed(entries)
    ]
    return {"batch_id": batch_id, "trend_last_3_shifts": trend_data}



@app.get("/batches/{batch_id}/export")
def export_batch_excel(batch_id: int, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    batch = db.query(Batch).filter(Batch.id == batch_id, Batch.tenant_id == tenant.id).first()
    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    entries = db.query(ShiftEntry).filter(ShiftEntry.batch_id == batch.id).all()

    # Prepare DataFrame
    data = []
    for e in entries:
        data.append({
            "Date": e.date,
            "Shift": e.shift_no.value,
            "Energy KWH": float(e.energy_kwh),
            "Unit Price KWH": float(e.unit_price_kwh),
            "Energy Cost": float(e.energy_cost),
            "Machine Hours": float(e.machine_hours),
            "Unit Price Machine Hour": float(e.unit_price_machine_hour),
            "Machine Cost": float(e.machine_cost),
            "Worker Hours": float(e.worker_hours),
            "Unit Price Worker Hour": float(e.unit_price_worker_hour),
            "Worker Cost": float(e.worker_cost),
            "Output Units": e.output_units,
            "Total Cost": float(e.total_cost),
            "Productivity Ratio": float(e.output_units / e.total_cost) if e.total_cost > 0 else 0
        })
    
    df = pd.DataFrame(data)

    # Save Excel temporarily
    file_path = f"batch_{batch_id}_report.xlsx"
    df.to_excel(file_path, index=False)

    # Return file
    response = FileResponse(file_path, filename=f"batch_{batch_id}_report.xlsx", media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')

    # Optional: delete after sending
    # os.remove(file_path)

    return response

@app.get("/batches/{batch_id}/daily_report")
def daily_report(batch_id: int, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    batch = db.query(Batch).filter(Batch.id == batch_id, Batch.tenant_id == tenant.id).first()
    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    # Group by date
    results = (
        db.query(
            ShiftEntry.date,
            func.sum(ShiftEntry.energy_kwh).label("total_energy"),
            func.sum(ShiftEntry.machine_hours).label("total_machine"),
            func.sum(ShiftEntry.worker_hours).label("total_worker"),
            func.sum(ShiftEntry.output_units).label("total_output"),
            func.sum(ShiftEntry.total_cost).label("total_cost")
        )
        .filter(ShiftEntry.batch_id == batch.id)
        .group_by(ShiftEntry.date)
        .order_by(ShiftEntry.date)
        .all()
    )

    daily_summary = []
    for r in results:
        daily_summary.append({
            "date": r.date,
            "total_energy": float(r.total_energy),
            "total_machine_hours": float(r.total_machine),
            "total_worker_hours": float(r.total_worker),
            "total_output_units": int(r.total_output),
            "total_cost": float(r.total_cost),
            "productivity_ratio": float(r.total_output / r.total_cost) if r.total_cost > 0 else 0
        })

    return {"batch_id": batch.id, "daily_summary": daily_summary}

@app.get("/products/{product_id}/trend_last_batches")
def trend_last_batches(product_id: int, n: int = 3, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    # Validate product
    product = db.query(Product).filter(Product.id == product_id, Product.tenant_id == tenant.id).first()
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")

    last_batches = (
        db.query(Batch)
        .filter(Batch.product_id == product_id, Batch.tenant_id == tenant.id)
        .order_by(Batch.start_date.desc())
        .limit(n)
        .all()
    )

    trend_data = []
    for batch in reversed(last_batches):
        entries = db.query(ShiftEntry).filter(ShiftEntry.batch_id == batch.id).all()
        total_output = sum(e.output_units for e in entries)
        total_cost = sum(e.total_cost for e in entries)
        trend_data.append({
            "batch_no": batch.batch_no,
            "start_date": batch.start_date,
            "end_date": batch.end_date,
            "total_output": total_output,
            "total_cost": float(total_cost),
            "cost_per_unit": float(total_cost / total_output) if total_output > 0 else 0,
            "productivity_ratio": float(total_output / total_cost) if total_cost > 0 else 0
        })

    return {"product_id": product.id, "trend_last_batches": trend_data}




# -----------------------------
# Batch-level AI Analysis Endpoint
# -----------------------------
@app.get("/batches/{batch_id}/ai_analysis")
def batch_ai_analysis(batch_id: int, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    batch = db.query(Batch).filter(Batch.id == batch_id, Batch.tenant_id == tenant.id).first()
    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")
    return ai_batch_analysis(db, batch)

# -----------------------------
# Product-level AI Trend Endpoint
# -----------------------------
@app.get("/products/{product_id}/ai_trend")
def product_ai_trend(product_id: int, n: int = 3, db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    product = db.query(Product).filter(Product.id == product_id, Product.tenant_id == tenant.id).first()
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    last_batches = db.query(Batch).filter(Batch.product_id == product_id, Batch.tenant_id == tenant.id).order_by(Batch.start_date.desc()).limit(n).all()
    return ai_product_trend(db, product_id, last_batches)

# -----------------------------
# RAG Chatbot Endpoint
# -----------------------------


class ChatQuerySchema(BaseModel):
    query: str






@app.get("/dashboard/summary")
def dashboard_summary(db: Session = Depends(get_db), tenant: Tenant = Depends(get_current_user)):
    total_products = db.query(Product).filter_by(tenant_id=tenant.id).count()
    total_batches = db.query(Batch).filter_by(tenant_id=tenant.id).count()
    shifts_today = (
        db.query(ShiftEntry)
        .filter(ShiftEntry.tenant_id == tenant.id, ShiftEntry.date == date.today())
        .count()
    )
    total_output = (
        db.query(func.sum(ShiftEntry.output_units))
        .filter(ShiftEntry.tenant_id == tenant.id)
        .scalar()
    ) or 0
    avg_energy = (
        db.query(func.avg(ShiftEntry.energy_kwh))
        .filter(ShiftEntry.tenant_id == tenant.id)
        .scalar()
    ) or 0
    avg_cost = (
        db.query(func.avg(ShiftEntry.total_cost / ShiftEntry.output_units))
        .filter(ShiftEntry.tenant_id == tenant.id, ShiftEntry.output_units > 0)
        .scalar()
    ) or 0

    # âœ… First, get batch safely
    batch = db.query(Batch).filter_by(tenant_id=tenant.id).first()
    if not batch:
        return {
            "totalProducts": total_products,
            "totalBatches": total_batches,
            "shiftsToday": shifts_today,
            "totalOutput": total_output,
            "avgEnergy": round(avg_energy, 2),
            "avgCost": round(avg_cost, 2),
            "inefficiencies": 0,
            "predictedOutput": 0,
            "message": "No batch found for tenant"
        }

    # âœ… Only call if batch exists
    ai_result = ai_batch_analysis(db, batch)

    return {
        "totalProducts": total_products,
        "totalBatches": total_batches,
        "shiftsToday": shifts_today,
        "totalOutput": total_output,
        "avgEnergy": round(avg_energy, 2),
        "avgCost": round(avg_cost, 2),
        "inefficiencies": len(ai_result.get("top_3_inefficiencies", [])),
        "predictedOutput": ai_result.get("predicted_output_next_shift", 0),
    }
